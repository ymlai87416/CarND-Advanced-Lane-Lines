{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import traceback\n",
    "from PIL import Image\n",
    "import scipy.ndimage\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import skimage.filters\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera:\n",
    "\n",
    "    def __init__(self, calibration_src):\n",
    "        self.objpoints, self.imgpoints = self.__find_camera_distortion_mapping(calibration_src)\n",
    "        self.image_shape = (1280, 720)\n",
    "        w,h = self.image_shape\n",
    "        x,y = 0.5*w, 0.8*h\n",
    "        \n",
    "        if False:\n",
    "            self.src = np.float32([[200./1280*w,720./720*h],\n",
    "                          [453./1280*w,547./720*h],\n",
    "                          [835./1280*w,547./720*h],\n",
    "                          [1100./1280*w,720./720*h]])\n",
    "            self.dst = np.float32([[(w-x)/2.,h],\n",
    "                          [(w-x)/2.,0.82*h],\n",
    "                          [(w+x)/2.,0.82*h],\n",
    "                          [(w+x)/2.,h]])\n",
    "\n",
    "        self.src = np.array([[(189, 720),\n",
    "                              (590, 450),\n",
    "                              (689, 450),\n",
    "                              (1135, 720)\n",
    "                              ]], dtype=np.float32)\n",
    "\n",
    "        self.dst = np.array([[(315, 720),\n",
    "                              (315, 0),\n",
    "                              (960, 0),\n",
    "                              (960, 720)\n",
    "                              ]], dtype=np.float32)\n",
    "        \n",
    "        self.inter_right = np.array([[(315, 720),\n",
    "                              (950,385),\n",
    "                              (1591,385),\n",
    "                              (960, 720)\n",
    "                              ]], dtype=np.float32)\n",
    "        \n",
    "        self.inter_left = np.array([[(315, 720),\n",
    "                              (-320, 385),\n",
    "                              (329, 385),\n",
    "                              (960, 720)\n",
    "                              ]], dtype=np.float32)\n",
    "       \n",
    "        \n",
    "        self.bird_view_image_size = (1280, 720)\n",
    "\n",
    "        self.M = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.Minv = cv2.getPerspectiveTransform(self.dst, self.src)\n",
    "        \n",
    "        self.M_left = cv2.getPerspectiveTransform(self.inter_left, self.dst)\n",
    "        self.Minv_left = cv2.getPerspectiveTransform(self.dst, self.inter_left)\n",
    "        \n",
    "        self.M_right = cv2.getPerspectiveTransform(self.inter_right, self.dst) \n",
    "        self.Minv_right = cv2.getPerspectiveTransform(self.dst, self.inter_right)\n",
    "        \n",
    "        self.ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
    "        self.xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "        \n",
    "        ret, mtx, dist, rvecs, tvecs = \\\n",
    "            cv2.calibrateCamera(self.objpoints, self.imgpoints, self.image_shape, None, None)\n",
    "            \n",
    "        self.mtx = mtx\n",
    "        self.dist = dist\n",
    "\n",
    "    def __find_camera_distortion_mapping(self, src):\n",
    "        # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "        objp = np.zeros((6 * 9, 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "        # Arrays to store object points and image points from all the images.\n",
    "        objpoints = []  # 3d points in real world space\n",
    "        imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "        # Make a list of calibration images\n",
    "        images = glob.glob(src + '/calibration*.jpg')\n",
    "\n",
    "        # Step through the list and search for chessboard corners\n",
    "        for i, fname in enumerate(images):\n",
    "            img = cv2.imread(fname)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Find the chessboard corners\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "\n",
    "            # If found, add object points, image points\n",
    "            if ret :\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "\n",
    "        return objpoints, imgpoints\n",
    "\n",
    "    def cal_undistort(self, img):\n",
    "        undist = cv2.undistort(img, self.mtx, self.dist, None, self.mtx)\n",
    "        return undist\n",
    "\n",
    "    def transform_to_bird_view(self, image):\n",
    "        warped = cv2.warpPerspective(image, self.M, self.bird_view_image_size)\n",
    "        return warped\n",
    "\n",
    "    def transform_to_camera_view(self, image):\n",
    "        warped = cv2.warpPerspective(image, self.Minv, self.image_shape)\n",
    "        return warped\n",
    "    \n",
    "    def transform_further_point_inv(self, points, direction):\n",
    "        if points is None:\n",
    "            return points\n",
    "        \n",
    "        if(direction > 0):\n",
    "            tpoints = cv2.perspectiveTransform(np.array([points], dtype='float32'), self.Minv_right)\n",
    "            tpoints = np.squeeze(tpoints, axis=0).astype(int)\n",
    "        elif(direction < 0):\n",
    "            tpoints = cv2.perspectiveTransform(np.array([points], dtype='float32'), self.Minv_left)\n",
    "            tpoints = np.squeeze(tpoints, axis=0).astype(int)\n",
    "        else:\n",
    "            tpoints = points\n",
    "            \n",
    "        return tpoints\n",
    "    \n",
    "    def transform_further(self, image, direction): \n",
    "        if(direction > 0):\n",
    "            warped = cv2.warpPerspective(image, self.M_right, self.bird_view_image_size)\n",
    "        elif(direction < 0):\n",
    "            warped = cv2.warpPerspective(image, self.M_left, self.bird_view_image_size)\n",
    "        else:\n",
    "            warped = np.copy(image)\n",
    "            \n",
    "        return warped\n",
    "            \n",
    "    def transform_further_inverse(self, image, direction): \n",
    "        if(direction > 0):\n",
    "            warped = cv2.warpPerspective(image, self.Minv_right, self.bird_view_image_size)\n",
    "        elif(direction < 0):\n",
    "            warped = cv2.warpPerspective(image, self.Minv_left, self.bird_view_image_size)\n",
    "        else:\n",
    "            warped = np.copy(image)\n",
    "            \n",
    "        return wraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "camera = Camera('./camera_cal')\n",
    "image_checkboard = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "undist_checkboard = camera.cal_undistort(image_checkboard)\n",
    "\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=2, figsize=(15,8))\n",
    "\n",
    "axarr[0].set_title(\"Original Image\")\n",
    "axarr[0].imshow(image_checkboard)\n",
    "\n",
    "axarr[1].set_title(\"Undistorted Image\")\n",
    "axarr[1].imshow(undist_checkboard)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "image_test1 = cv2.cvtColor(cv2.imread('./test_images/test1.jpg'), cv2.COLOR_BGR2RGB)\n",
    "undist_test1 = camera.cal_undistort(image_test1)\n",
    "\n",
    "fig, axarr = plt.subplots(nrows=1, ncols=2, figsize=(15,8))\n",
    "\n",
    "axarr[0].set_title(\"Original Image\")\n",
    "axarr[0].imshow(image_test1)\n",
    "\n",
    "axarr[1].set_title(\"Undistorted Image\")\n",
    "axarr[1].imshow(undist_test1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road feature detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadFeatureDetector:\n",
    "\n",
    "    class RoadFeatureDetectorParameter:\n",
    "        def __init__(self):\n",
    "            #Change your configuration here\n",
    "\n",
    "            #image\n",
    "            self.image = None\n",
    "            self.image_yuv = None\n",
    "            self.image_hsv = None\n",
    "            self.image_lab = None\n",
    "            self.image_enhanced = None\n",
    "            self.image_enhanced_yuv = None\n",
    "            self.image_enhanced_hsv = None\n",
    "            self.image_enhanced_lab = None\n",
    "\n",
    "            #MASKING\n",
    "            #image related\n",
    "            self.lower_half_start_y = 450\n",
    "            self.near_car_start_y = 600\n",
    "            #road detection\n",
    "            self.road_color_diff = 30 #15\n",
    "            self.road_closing_size = 70\n",
    "            self.road_dilate_size = 60 #10\n",
    "            #mask related\n",
    "            self.enable_color_mask = False\n",
    "            self.mask_dilate = 9\n",
    "            # remove non-line setting\n",
    "            self.non_line_closing_size = 13\n",
    "            self.non_line_opening_size = 60\n",
    "\n",
    "            # FEATURE EXTRACTION\n",
    "            #sobel absolute\n",
    "            self.abs_sobel_direction = 'x'\n",
    "            self.abs_sobel_low_threshold = 20\n",
    "            self.abs_sobel_high_threshold = 100\n",
    "            self.sobel_guassian_blur = 13\n",
    "            # sobel magnitude\n",
    "            self.abs_sobel_mag_threshold = 0\n",
    "            self.abs_sobel_mag_kernel = 255\n",
    "            # sobel direction\n",
    "            self.abs_sobel_dir_threshold = 0\n",
    "            self.abs_sobel_dir_kernel = np.pi / 2\n",
    "            # hsl detection\n",
    "            self.hsl_threshold = (0, 255)\n",
    "            #yellow detection\n",
    "            self.yellow_lower = 155\n",
    "            self.yellow_upper = 200\n",
    "            #white detection\n",
    "            self.white_intensity_threshold = None\n",
    "            self.white_intensity_threshold_low = None\n",
    "            #feature enable/disable\n",
    "            self.enable_hist_eq = False\n",
    "            \n",
    "            ##OUTPUT\n",
    "            self.output_mask_road = None\n",
    "            self.output_mask_yellow = None\n",
    "            self.output_mask_white = None\n",
    "            self.output_mask_edge = None\n",
    "            self.output_mask_combined = None\n",
    "\n",
    "            self.output_feature_yellow = None\n",
    "            self.output_feature_white = None\n",
    "            self.output_feature_edge = None\n",
    "            self.output_masked_feature = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.debug_dict = None\n",
    "        self.debug_flag = False\n",
    "\n",
    "    # Define a function that applies Sobel x or y,\n",
    "    # then takes an absolute value and applies a threshold.\n",
    "    # Note: calling your function with orient='x', thresh_min=5, thresh_max=100\n",
    "    # should produce output like the example image shown above this quiz.\n",
    "    def __abs_sobel_thresh(self, image_gray, orient='x', thresh_min=0, thresh_max=255, guassian_blur=13):\n",
    "        gray = cv2.GaussianBlur(image_gray, (guassian_blur, guassian_blur), 0)\n",
    "        # Apply x or y gradient with the OpenCV Sobel() function\n",
    "        # and take the absolute value\n",
    "        if orient == 'x':\n",
    "            abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "            if orient == 'y':\n",
    "                abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "            # Rescale back to 8 bit integer\n",
    "            scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "            # Create a copy and apply the threshold\n",
    "            binary_output = np.zeros_like(scaled_sobel)\n",
    "            # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "            binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "            return binary_output\n",
    "\n",
    "\n",
    "    # Define a function that applies Sobel x and y,\n",
    "    # then computes the magnitude of the gradient\n",
    "    # and applies a threshold\n",
    "    def __mag_thresh(self, image_gray, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "        # Apply x or y gradient with the OpenCV Sobel() function\n",
    "        # and take the absolute value\n",
    "        sobelx = (cv2.Sobel(image_gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "        sobely = (cv2.Sobel(image_gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "        mag_sobel = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "        # Rescale back to 8 bit integer\n",
    "        scaled_sobel = np.uint8(255 * mag_sobel / np.max(mag_sobel))\n",
    "        # Create a copy and apply the threshold\n",
    "        binary_output = np.zeros_like(scaled_sobel)\n",
    "        # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "        binary_output[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "\n",
    "        return binary_output\n",
    "\n",
    "\n",
    "    # Define a function that applies Sobel x and y,\n",
    "    # then computes the direction of the gradient\n",
    "    # and applies a threshold.\n",
    "    def __dir_threshold(self, image_gray, sobel_kernel=3, thresh=(0, np.pi / 2)):\n",
    "        # Apply x or y gradient with the OpenCV Sobel() function\n",
    "        # and take the absolute value\n",
    "        sobelx = np.absolute(cv2.Sobel(image_gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "        sobely = np.absolute(cv2.Sobel(image_gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "        mag_sobel = np.arctan2(sobely, sobelx)\n",
    "        # Create a copy and apply the threshold\n",
    "        binary_output = np.zeros_like(mag_sobel)\n",
    "        # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "        binary_output[(mag_sobel >= thresh[0]) & (mag_sobel <= thresh[1])] = 1\n",
    "\n",
    "        return binary_output\n",
    "\n",
    "\n",
    "    # Define a function that thresholds the S-channel of HLS\n",
    "    # Use exclusive lower bound (>) and inclusive upper (<=)\n",
    "    def __hls_select(self, img, thresh=(0, 255)):\n",
    "        # 1) Convert to HLS color space\n",
    "        # 2) Apply a threshold to the S channel\n",
    "        # 3) Return a binary image of threshold result\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        s_channel = hls[:, :, 2]\n",
    "        binary_output = np.zeros_like(s_channel)\n",
    "        binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "\n",
    "        return binary_output\n",
    "\n",
    "    def __yellow_color(self, image_lab, lower_yellow, upper_yellow, dilate_kernel_size):\n",
    "        b_channel = image_lab[:,:,2]\n",
    "        # Threshold the HSV image to get only yellow colors\n",
    "        mask = np.zeros_like(b_channel, dtype=np.uint8)\n",
    "\n",
    "        mask[(b_channel >= lower_yellow) & (b_channel <= upper_yellow)] = 1\n",
    "\n",
    "        if(dilate_kernel_size > 0):\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (dilate_kernel_size, dilate_kernel_size))\n",
    "            mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "        \n",
    "        mask[mask > 0] = 1\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def __white_color(self, image_lab, lower_white, dilate_kernel_size):\n",
    "        l_channel = image_lab[:,:,0]\n",
    "        mask = np.zeros_like(l_channel, dtype=np.uint8)\n",
    "\n",
    "        mask[(l_channel >= lower_white) & (l_channel <= 255)] = 1\n",
    "        \n",
    "        if(dilate_kernel_size > 0):\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (dilate_kernel_size, dilate_kernel_size))\n",
    "            mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "            \n",
    "        mask[mask > 0] = 1\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def __highlight_horizontal_line(self, image):\n",
    "        def adoptive_canny(img, threshold):\n",
    "            ret,thresh1 = cv2.threshold(img , 0,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU);\n",
    "            cannyThresh = threshold * ret;\n",
    "            return cv2.Canny(img,cannyThresh,ret);\n",
    "\n",
    "        img_canny = adoptive_canny(image, 5)\n",
    "        img_ver = skimage.filters.sobel_v(img_canny)\n",
    "        img_ver = np.abs(img_ver) * 255\n",
    "\n",
    "        return img_ver\n",
    "    \n",
    "    def remove_non_line_structure(self, image):\n",
    "        process_param = self.RoadFeatureDetectorParameter()\n",
    "        \n",
    "        return self.__remove_non_line_structure(image, process_param.non_line_closing_size, process_param.non_line_opening_size)\n",
    "        \n",
    "    def __remove_non_line_structure(self, image, close_ksize, open_ksize):\n",
    "        ckernel = cv2.getStructuringElement(cv2.MORPH_RECT,(close_ksize,close_ksize))\n",
    "        okernel = cv2.getStructuringElement(cv2.MORPH_RECT,(open_ksize,open_ksize))\n",
    "\n",
    "        image_close = cv2.morphologyEx(image, cv2.MORPH_CLOSE, ckernel)\n",
    "        image_open = cv2.morphologyEx(image_close, cv2.MORPH_OPEN, okernel)\n",
    "        final_img = np.zeros_like(image_close, dtype=np.uint8)\n",
    "        final_img[(image > 0) & (image_open==0)]=1\n",
    "\n",
    "        return final_img\n",
    "\n",
    "    def __percentile(self, data, percentile):\n",
    "        size = len(data)\n",
    "        return data[int(math.ceil((size * percentile) / 100)) - 1]\n",
    "    \n",
    "    def __gary_road_detector_helper(self, image_hsv, seed, road_color_diff, \\\n",
    "                             road_closing_size, road_dilate_size):\n",
    "        hsv = image_hsv\n",
    "        h,w = hsv.shape[:-1]\n",
    "        img_x = np.zeros_like(hsv[:,:,0])\n",
    "        \n",
    "        mask = np.ones_like(hsv[:,:,1], dtype=np.uint8)\n",
    "        mask[(hsv[:,:,1] > 90) & (hsv[:,:,2] > 60)] = 0\n",
    "        mask[hsv[:,:,2] > 225] = 0\n",
    "        \n",
    "        h_channel = image_hsv[:,:,0]\n",
    "        s_channel = image_hsv[:,:,1]\n",
    "        \n",
    "        base_h = h_channel[seed[1], seed[0]]\n",
    "        base_s = s_channel[seed[1], seed[0]]\n",
    "        min_th_h, max_th_h = max(0, base_h-road_color_diff),  min(255, base_h+road_color_diff)\n",
    "        min_th_s, max_th_s = max(0, base_s-road_color_diff),  min(255, base_s+road_color_diff)\n",
    "        \n",
    "        img_x[(mask == 1) & \n",
    "              (((h_channel >= min_th_h) & (h_channel <= max_th_h)) |\n",
    "              ((s_channel >= min_th_s) & (s_channel <= max_th_s))) ] = 1\n",
    "        \n",
    "        mask = np.zeros((h+2,w+2),np.uint8)\n",
    "        mask[0,:] = 1\n",
    "        mask[:,0] = 1\n",
    "        mask[h+1, :] = 1\n",
    "        mask[:, w+1] = 1\n",
    "        \n",
    "        floodflags = 4\n",
    "        num,im,mask,rect = cv2.floodFill(img_x, mask, seed, 255, 0, 0, floodflags)\n",
    "        im[(im!= 255)] = 0\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (road_dilate_size, road_dilate_size))\n",
    "        im = cv2.dilate(im, kernel, iterations=1)\n",
    "        im[im > 0]=1\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def __gray_road_detector(self, seeds, image_hsv, road_color_diff, \\\n",
    "                             road_closing_size, road_dilate_size):\n",
    "        #TODO: testing\n",
    "        #image_hsv = cv2.cvtColor(cv2.cvtColor(image_hsv, cv2.COLOR_HSV2RGB), cv2.COLOR_RGB2HLS)\n",
    "        h,w = image_hsv.shape[:-1]\n",
    "        \n",
    "        im = np.zeros((h, w),np.uint8)\n",
    "        for seed in seeds:\n",
    "            im_t = self.__gary_road_detector_helper(image_hsv, seed, road_color_diff, \\\n",
    "                             road_closing_size, road_dilate_size)\n",
    "            im[im_t == 1] = 1\n",
    "        \n",
    "        return im\n",
    "\n",
    "    def __equalize_intensity(self, image):\n",
    "        ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb);\n",
    "        channels = cv2.split(ycrcb)\n",
    "        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))\n",
    "        channels[0] = clahe.apply(channels[0])\n",
    "\n",
    "        ycrcb = cv2.merge(channels)\n",
    "\n",
    "        result = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2RGB)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __create_mask(self, param):\n",
    "        h,w = param.image_hsv.shape[:-1]\n",
    "        seeds = [(w//2,h*6//8), (w*8//20,h*7//8), \n",
    "                 (w*9//20,h*7//8), (w*12//20, h*7//8), (w*11//20,h*7//8)]\n",
    "        g_binary = self.__gray_road_detector(seeds, param.image_hsv, param.road_color_diff,\n",
    "                                             param.road_closing_size, param.road_dilate_size)\n",
    "        \n",
    "        param.white_intensity_threshold, param.white_intensity_threshold_low \\\n",
    "            = self.__find_white_threshold(g_binary, param.image_enhanced_lab[:,:,0])\n",
    "        #param.white_intensity_threshold = min(param.white_intensity_threshold, 225)\n",
    "        \n",
    "        param.output_mask_road = g_binary\n",
    "        \n",
    "        mask_clr = g_binary\n",
    "            \n",
    "        if self.debug_flag:\n",
    "            debug_image = np.dstack(( np.zeros_like(g_binary), g_binary, np.zeros_like(g_binary))) * 255\n",
    "            for seed in seeds:\n",
    "                cv2.circle(debug_image, seed, 5, (0,0,255), -1)\n",
    "                        \n",
    "            nonzero_ptg= len(debug_image.nonzero()[0]) * 1.0 / debug_image.size * 100\n",
    "            cv2.putText(debug_image, \"COVER PERCENTAGE: %d%%\" % nonzero_ptg, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,\n",
    "                        cv2.LINE_AA)\n",
    "            \n",
    "            self.debug_dict['mask'] = debug_image\n",
    "            \n",
    "        return mask_clr\n",
    "\n",
    "    def __create_feature(self, param):\n",
    "        denoise_image = cv2.fastNlMeansDenoising(param.image_yuv[:,:,0],None,10,7,21)\n",
    "        sxbinary = self.__abs_sobel_thresh(denoise_image, param.abs_sobel_direction,\n",
    "                                           param.abs_sobel_low_threshold, param.abs_sobel_high_threshold)\n",
    "        s_yellow = self.__yellow_color(param.image_enhanced_lab, param.yellow_lower, param.yellow_upper, 0)\n",
    "        \n",
    "        #lower_white = min(param.white_intensity_threshold, 225)\n",
    "        s_white = self.__white_color(param.image_enhanced_lab, param.white_intensity_threshold, 0)\n",
    "        if np.count_nonzero(s_white) > np.size(param.image_yuv[:,:,0]) * 0.05 :\n",
    "            s_white = np.zeros_like(param.image_yuv[:,:,0])\n",
    "\n",
    "        #if param.remove_nonline_in_feature:\n",
    "        #    sxbinary = self.__remove_non_line_structure(sxbinary, param.non_line_closing_size, param.non_line_opening_size)\n",
    "        #    s_yellow = self.__remove_non_line_structure(s_yellow, param.non_line_closing_size, param.non_line_opening_size)\n",
    "        #    s_white = self.__remove_non_line_structure(s_white, param.non_line_closing_size, param.non_line_opening_size)\n",
    "        \n",
    "        # Combine the two binary thresholds\n",
    "        combined_feature = np.zeros_like(s_yellow)\n",
    "        combined_feature[(s_yellow == 1) | (sxbinary == 1) | (s_white == 1)] = 1\n",
    "\n",
    "        param.output_feature_yellow = s_yellow\n",
    "        param.output_feature_white = s_white\n",
    "        param.output_feature_edge = sxbinary\n",
    "\n",
    "        return combined_feature\n",
    "\n",
    "    def __is_masking_good(self, mask):\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 6\n",
    "        minpix = 25\n",
    "        # Set height of windows\n",
    "        window_height = np.int(mask.shape[0] / nwindows)\n",
    "\n",
    "        nonzero = mask.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        bad_window_score = 0\n",
    "\n",
    "        for window in range(nwindows):\n",
    "            win_y_low = mask.shape[0] - (window + 1) * window_height\n",
    "            win_y_high = mask.shape[0] - window * window_height\n",
    "            good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high)).nonzero()[0]\n",
    "\n",
    "            if (len(good_inds) < minpix):\n",
    "                bad_window_score = bad_window_score + window #close to base have a heavier weighting\n",
    "\n",
    "        return bad_window_score > 5\n",
    "\n",
    "    def __find_white_threshold(self, road_mask, image_gray):\n",
    "        data = image_gray[image_gray.nonzero()].ravel()\n",
    "        data = np.sort(data)\n",
    "        thresh = min(self.__percentile(data, 99)+1, 255)\n",
    "        thresh_low = min(self.__percentile(data, 97)+1, 255)\n",
    "        \n",
    "        return thresh, thresh_low\n",
    "    \n",
    "    def collect_road_features(self, image):\n",
    "        self.debug_dict = {}\n",
    "        process_param = self.RoadFeatureDetectorParameter()\n",
    "        \n",
    "        if process_param.enable_hist_eq:\n",
    "            image_enhanced = self.__equalize_intensity(image)\n",
    "        else:\n",
    "            image_enhanced = image\n",
    "\n",
    "        process_param.image = image\n",
    "        process_param.image_yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        process_param.image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        process_param.image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        \n",
    "        process_param.image_enhanced = image_enhanced\n",
    "        process_param.image_enhanced_yuv = cv2.cvtColor(image_enhanced, cv2.COLOR_RGB2YUV)\n",
    "        process_param.image_enhanced_hsv = cv2.cvtColor(image_enhanced, cv2.COLOR_RGB2HSV)\n",
    "        process_param.image_enhanced_lab = cv2.cvtColor(image_enhanced, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "        mask = self.__create_mask(process_param)\n",
    "        color = self.__create_feature(process_param)\n",
    "\n",
    "        self.debug_dict['enhanced'] = image_enhanced\n",
    "        \n",
    "        process_param.output_feature_yellow[(mask == 0)] = 0\n",
    "        process_param.output_feature_white[(mask == 0)] = 0\n",
    "        process_param.output_feature_edge[(mask == 0)] = 0\n",
    "        \n",
    "        return process_param.output_feature_edge, process_param.output_feature_white, process_param.output_feature_yellow\n",
    "\n",
    "    def get_debug_info(self):\n",
    "        return self.debug_dict;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lane:\n",
    "    def __init__(self, polyfit):\n",
    "        self.polyfit = polyfit\n",
    "\n",
    "    def set_lane_line_pixel(self, pixels):\n",
    "        self.pixels = pixels\n",
    "\n",
    "    def set_lane_line_detection_windows(self, windows_pos, is_windows_good):\n",
    "        self.window_pos = windows_pos\n",
    "        self.is_windows_good = is_windows_good\n",
    "\n",
    "    def calc_real_scale(self, ym_per_pix, xm_per_pix):\n",
    "        self.polyfit_real_scale = np.zeros(self.polyfit.shape)\n",
    "\n",
    "        self.polyfit_real_scale[0] = self.polyfit[0] / ym_per_pix / ym_per_pix * xm_per_pix\n",
    "        self.polyfit_real_scale[1] = self.polyfit[1] / ym_per_pix * xm_per_pix\n",
    "        self.polyfit_real_scale[2] = self.polyfit[2] * xm_per_pix\n",
    "\n",
    "        return self.polyfit_real_scale\n",
    "\n",
    "    def line_base_real_scale(self, y):\n",
    "        return self.polyfit_real_scale[0] * y ** 2 + self.polyfit_real_scale[1] * y + self.polyfit_real_scale[2]\n",
    "\n",
    "    def line_curvature_real_scale(self, y):\n",
    "        ''' y is the real scale in bird view'''\n",
    "        return ((1 + (2 * self.polyfit_real_scale[0] * y + self.polyfit_real_scale[1]) ** 2) ** 1.5) / np.absolute(\n",
    "            2 * self.polyfit_real_scale[0])\n",
    "\n",
    "    def line_x_pos(self, y):\n",
    "        return self.polyfit[0] * y ** 2 + self.polyfit[1] * y + self.polyfit[2]\n",
    "\n",
    "    def line_curvature(self, y):\n",
    "        ''' y is the real scale in bird view'''\n",
    "        return ((1 + (2 * self.polyfit[0] * y + self.polyfit[1]) ** 2) ** 1.5) / np.absolute(\n",
    "            2 * self.polyfit[0])\n",
    "\n",
    "    def error_rate(self):\n",
    "        if self.is_windows_good is None:\n",
    "            return 0\n",
    "        else: \n",
    "            return np.count_nonzero(self.is_windows_good == False) / len(self.is_windows_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneDetectorParam():\n",
    "    def __init__(self):\n",
    "        self.image_shape = None\n",
    "        self.find_lane_left_lane_pos = 310\n",
    "        self.find_lane_right_lane_pos = 960\n",
    "        self.find_lane_lane_sigma = 200\n",
    "        self.find_lane_no_detect_window_y = 15\n",
    "        self.find_lane_window_margin_x = 100\n",
    "        self.find_lane_min_pixel = 300 #30\n",
    "        self.find_lane_weighting = lambda norm_x, norm_y: norm_y ** 2\n",
    "        self.camera_dir = './camera_cal'\n",
    "        #remove non-line in features\n",
    "        self.remove_nonline_in_feature = True\n",
    "        # pixel property weighting\n",
    "        self.yellow_pixel_weighting = 5\n",
    "        self.white_pixel_weighting = 2\n",
    "        self.edge_pixel_weighting = 1\n",
    "        \n",
    "class LaneDetector():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.param = LaneDetectorParam()\n",
    "        self.camera = Camera(self.param.camera_dir)\n",
    "        self.road_feature_detector = RoadFeatureDetector()\n",
    "        self.__debug_flag = False\n",
    "        self.__debug_dict = None\n",
    "        self.exp_lane_width_meter =3.7\n",
    "\n",
    "    def set_debug_flag(self, value):\n",
    "        self.__debug_flag = value\n",
    "        self.camera.debug_flag = value\n",
    "        self.road_feature_detector.debug_flag = value\n",
    "\n",
    "    def __birdview_pixel_weighting(self, shape, left_lane_base, right_lane_base, y_dist_max, y_dist_w, sigma):\n",
    "        x_left = norm(loc=left_lane_base, scale=sigma)\n",
    "        x_right = norm(loc=right_lane_base, scale=sigma)\n",
    "        x_idx = np.arange(0, shape[0], 1)\n",
    "        x = (x_left.pdf(x_idx) + x_right.pdf(x_idx)) / (0.3989 / sigma) * 4\n",
    "        y = np.append(np.zeros(y_dist_max), np.linspace(1, y_dist_w, shape[1] - y_dist_max))\n",
    "        xv, yv = np.meshgrid(x, y)\n",
    "        result = xv * yv\n",
    "\n",
    "        np.clip(result, 0, 255, out=result)\n",
    "        return result.astype(np.uint8)\n",
    "\n",
    "    def __draw_histogram(self, histogram, remarks=\"\"):\n",
    "        fig = Figure(figsize=(3, 1))\n",
    "        fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        ax = fig.gca()\n",
    "\n",
    "        ax.plot(histogram)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "\n",
    "        canvas.draw()  # draw the canvas, cache the renderer\n",
    "\n",
    "        width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "        image = np.fromstring(canvas.tostring_rgb(), dtype='uint8').reshape(int(height), int(width), 3)\n",
    "        \n",
    "        cv2.putText(image, remarks, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __find_left_and_right_base(self, binary_warped, left_lane, right_lane, lane_sigma):\n",
    "        shape = binary_warped.shape[1::-1]\n",
    "        weights = self.__birdview_pixel_weighting(shape, left_lane, right_lane, shape[1] // 2, 3, lane_sigma)\n",
    "        weighted_binary_warped = weights * binary_warped\n",
    "        histogram_50 = np.sum(weighted_binary_warped[weighted_binary_warped.shape[0] // 2:, :], axis=0)\n",
    "        histogram_25 = np.sum(weighted_binary_warped[weighted_binary_warped.shape[0] * 3 // 4 :, :], axis=0)\n",
    "        \n",
    "        midpoint = np.int(histogram_50.shape[0] // 2)\n",
    "        leftx_base = (np.argmax(histogram_50[:midpoint]) + np.argmax(histogram_25[:midpoint]) *2)//3\n",
    "        rightx_base = (np.argmax(histogram_50[midpoint:]) + np.argmax(histogram_25[midpoint:]) * 2)//3 + midpoint\n",
    "        \n",
    "        if(self.__debug_flag):\n",
    "            self.__debug_dict['histogram'] = self.__draw_histogram(histogram_25, \"SIMPLE\")\n",
    "        \n",
    "        return leftx_base, rightx_base\n",
    "    \n",
    "    def __find_left_and_right_base_fix_width(self, binary_warped, spacing, left_lane, right_lane, lane_sigma):\n",
    "        shape = binary_warped.shape[1::-1]\n",
    "        weights = self.__birdview_pixel_weighting(shape, left_lane, right_lane, shape[1] // 2, 3, lane_sigma)\n",
    "        weighted_binary_warped = binary_warped \n",
    "        \n",
    "        histogram_50 = np.sum(weighted_binary_warped[weighted_binary_warped.shape[0] // 2:, :], axis=0)\n",
    "        histogram_25 = np.sum(weighted_binary_warped[weighted_binary_warped.shape[0] * 3 // 4 :, :], axis=0)\n",
    "        \n",
    "        histogram = histogram_50 + histogram_25 * 2\n",
    "        \n",
    "        midpoint = np.int(histogram_50.shape[0] // 2)\n",
    "        leftx_base = (np.argmax(histogram_50[:midpoint]) + np.argmax(histogram_25[:midpoint]) *2)//3\n",
    "        rightx_base = (np.argmax(histogram_50[midpoint:]) + np.argmax(histogram_25[midpoint:]) * 2)//3 + midpoint\n",
    "        \n",
    "        rightx_base_st = int(leftx_base + spacing * 0.7)\n",
    "        rightx_base_2 = (np.argmax(histogram_50[rightx_base_st:]) \n",
    "                         + np.argmax(histogram_25[rightx_base_st:]) * 2)//3 + rightx_base_st\n",
    "        \n",
    "        leftx_base_st = int(rightx_base - spacing * 0.7)\n",
    "        leftx_base_2 = (np.argmax(histogram_50[:leftx_base_st]) + np.argmax(histogram_25[:leftx_base_st]) * 2)//3\n",
    "        \n",
    "        if(self.__debug_flag):\n",
    "            self.__debug_dict['histogram'] = self.__draw_histogram(histogram, \"FIX W\")\n",
    "        \n",
    "        if(max(histogram[leftx_base], histogram[rightx_base_2]) > max(histogram[leftx_base_2], histogram[rightx_base])):\n",
    "            return leftx_base, rightx_base_2\n",
    "        else:\n",
    "            return leftx_base_2, rightx_base\n",
    "        \n",
    "    def __find_left_and_right_base_conv(self, binary_warped, window, left_lane, right_lane, lane_sigma): \n",
    "        shape = binary_warped.shape[1::-1]\n",
    "        window_width = len(window)\n",
    "        weights = self.__birdview_pixel_weighting(shape, left_lane, right_lane, shape[1] // 2, 3, lane_sigma)\n",
    "        weighted_binary_warped = weights * binary_warped\n",
    "        # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "        histogram = np.sum(binary_warped[int(3*weighted_binary_warped.shape[0]/4):,:], axis=0)\n",
    "        \n",
    "        l_sum = histogram[:int(weighted_binary_warped.shape[1]/2)]\n",
    "        l_center = np.argmax(np.convolve(window,l_sum))-window_width//2\n",
    "        r_sum = histogram[int(weighted_binary_warped.shape[1]/2):]\n",
    "        r_center = np.argmax(np.convolve(window,r_sum))-window_width//2+int(weighted_binary_warped.shape[1]/2)\n",
    "        \n",
    "        if(self.__debug_flag):\n",
    "            self.__debug_dict['histogram'] = self.__draw_histogram(histogram, \"CONV\")\n",
    "        \n",
    "        return l_center, r_center\n",
    "    \n",
    "    def create_reorder_array(self, min_index, max_index):\n",
    "        mid = (max_index - min_index)//2\n",
    "        result = np.zeros(max_index - min_index, dtype=np.int)\n",
    "        left = np.arange(0, mid)\n",
    "        left = left[::-1]\n",
    "        right = np.arange(mid, max_index - min_index)\n",
    "        result[0::2] = right\n",
    "        result[1::2] = left\n",
    "\n",
    "        return np.array(result)\n",
    "    \n",
    "    def __find_left_and_right_lane_conv(self, binary_warped, weighting_func, left_lane = 310, right_lane = 960, lane_sigma = 200,\n",
    "                                   no_detect_window_y = 27, window_margin_x = 100, min_pixel = 20, direction = 0):\n",
    "        # transform the image here given the hints\n",
    "        binary_warped = self.camera.transform_further(binary_warped, direction)\n",
    "        \n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "        window_width = 50 \n",
    "        window_height = np.int(binary_warped.shape[0] / no_detect_window_y)\n",
    "        margin = window_margin_x\n",
    "        minpix = min_pixel\n",
    "\n",
    "        window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "\n",
    "        # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "        # and then np.convolve the vertical image slice with the window template \n",
    "\n",
    "        l_center, r_center = self.__find_left_and_right_base_conv(binary_warped, window, left_lane, right_lane, lane_sigma)\n",
    "        \n",
    "        exp_spacing = int(self.exp_lane_width_meter / self.camera.xm_per_pix)\n",
    "        if abs(l_center - r_center) < exp_spacing * 0.75 or abs(l_center - r_center) > exp_spacing:\n",
    "            l_center, r_center = self.__find_left_and_right_base_fix_width(binary_warped, exp_spacing, left_lane, right_lane, lane_sigma)\n",
    "        \n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        left_windows = []\n",
    "        right_windows = []\n",
    "        is_left_window_good = []\n",
    "        is_right_window_good = []\n",
    "        leftw = []\n",
    "        rightw = []\n",
    "        consecutive_bad_left = 0\n",
    "        consecutive_bad_right = 0\n",
    "        current_leftw = 1\n",
    "        current_rightw = 1\n",
    "        \n",
    "        win_y_low = int(binary_warped.shape[0]-window_height)\n",
    "        win_y_high = int(binary_warped.shape[0])\n",
    "        win_xleft_low = l_center - window_width//2\n",
    "        win_xleft_high  = l_center + window_width//2\n",
    "        win_xright_low = r_center - window_width//2\n",
    "        win_xright_high = r_center + window_width//2\n",
    "        left_windows.append((win_xleft_low, win_y_low, win_xleft_high, win_y_high))\n",
    "        right_windows.append((win_xright_low, win_y_low, win_xright_high, win_y_high))\n",
    "\n",
    "        # Go through each layer looking for max pixel locations\n",
    "        for level in range(1,(int)(binary_warped.shape[0]/window_height)):\n",
    "            win_y_low = int(binary_warped.shape[0]-(level+1)*window_height)\n",
    "            win_y_high = int(binary_warped.shape[0]-level*window_height)\n",
    "            \n",
    "            # convolve the window into the vertical slice of the image\n",
    "            image_layer = np.sum(binary_warped[win_y_low:win_y_high,:], axis=0)\n",
    "            conv_signal = np.convolve(window, image_layer)\n",
    "            # Find the best left centroid by using past left center as a reference\n",
    "            # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "            offset = window_width//2\n",
    "            l_min_index = int(max(l_center+offset-margin,0))\n",
    "            l_max_index = int(min(l_center+offset+margin,binary_warped.shape[1]))\n",
    "            l_order = self.create_reorder_array(l_min_index, l_max_index)\n",
    "            l_conv_signal = (conv_signal[l_min_index:l_max_index])[l_order]\n",
    "            l_center_t = np.argmax(l_conv_signal)\n",
    "            l_center_t = l_order[l_center_t]+l_min_index-offset\n",
    "            # Find the best right centroid by using past right center as a reference\n",
    "            r_min_index = int(max(r_center+offset-margin,0))\n",
    "            r_max_index = int(min(r_center+offset+margin,binary_warped.shape[1]))\n",
    "            r_order = self.create_reorder_array(r_min_index, r_max_index)\n",
    "            r_conv_signal = (conv_signal[r_min_index:r_max_index])[r_order]\n",
    "            r_center_t = np.argmax(r_conv_signal)\n",
    "            r_center_t = r_order[r_center_t]+r_min_index-offset\n",
    "            \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            \n",
    "            win_xleft_low = l_center_t - offset\n",
    "            win_xleft_high  = l_center_t + offset\n",
    "            win_xright_low = r_center_t - offset\n",
    "            win_xright_high = r_center_t + offset\n",
    "            \n",
    "            left_windows.append((win_xleft_low, win_y_low, win_xleft_high, win_y_high))\n",
    "            right_windows.append((win_xright_low, win_y_low, win_xright_high, win_y_high))\n",
    "            \n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            \n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                is_left_window_good.append(True)\n",
    "                l_center = l_center_t\n",
    "                consecutive_bad_left = 0\n",
    "            else:\n",
    "                is_left_window_good.append(False)\n",
    "                consecutive_bad_left = consecutive_bad_left + 1\n",
    "            \n",
    "            if len(good_right_inds) > minpix:   \n",
    "                is_right_window_good.append(True)\n",
    "                r_center = r_center_t\n",
    "                consecutive_bad_right = 0\n",
    "            else:\n",
    "                is_right_window_good.append(False)\n",
    "                consecutive_bad_right = consecutive_bad_right + 1\n",
    "            \n",
    "            # early closing\n",
    "            if(consecutive_bad_left == 1 and\n",
    "               (l_center < 1.5 * window_width or l_center > binary_warped.shape[1] - 1.5 * window_width)):\n",
    "                current_leftw = 0\n",
    "            if(consecutive_bad_right == 1 and\n",
    "               (r_center < 1.5 * window_width or r_center > binary_warped.shape[1] - 1.5 * window_width)):\n",
    "                current_rightw = 0\n",
    "                \n",
    "            if(consecutive_bad_left == 2):\n",
    "                current_leftw = current_leftw / 2\n",
    "            elif(consecutive_bad_left == 4):\n",
    "                current_leftw = 0\n",
    "                \n",
    "            if(consecutive_bad_right == 2):\n",
    "                current_rightw = current_rightw / 2\n",
    "            elif(consecutive_bad_right == 4):\n",
    "                current_rightw = 0\n",
    "                \n",
    "            leftw_batch = binary_warped[nonzeroy[good_left_inds], nonzerox[good_left_inds]] * current_leftw\n",
    "            rightw_batch = binary_warped[nonzeroy[good_right_inds], nonzerox[good_right_inds]] * current_rightw\n",
    "               \n",
    "            leftw.append(leftw_batch)\n",
    "            rightw.append(rightw_batch)\n",
    "            \n",
    "                \n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        leftw = np.concatenate(leftw)\n",
    "        rightw = np.concatenate(rightw)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds]\n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        \n",
    "            \n",
    "        # reverse the bird view and the points here\n",
    "        pts_left = np.transpose(np.vstack([leftx, lefty]))\n",
    "        pts_right = np.transpose(np.vstack([rightx, righty]))\n",
    "        \n",
    "        pts_left = self.camera.transform_further_point_inv(pts_left, direction)\n",
    "        pts_right = self.camera.transform_further_point_inv(pts_right, direction)\n",
    "            \n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(pts_left[:, 1], pts_left[:, 0], 2, w=leftw)\n",
    "        right_fit = np.polyfit(pts_right[:, 1], pts_right[:, 0], 2, w=rightw)\n",
    "        \n",
    "        if(self.__debug_flag):\n",
    "            # add the line fitting result here\n",
    "            binary_warped[binary_warped>0] = 255\n",
    "            binary_warped = cv2.cvtColor(binary_warped, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            # draw the left rectangle\n",
    "            for rect, is_good in zip(left_windows, is_left_window_good):\n",
    "                if is_good:\n",
    "                    rect_color = (0, 255, 0)\n",
    "                else:\n",
    "                    rect_color = (255, 0, 0)\n",
    "                cv2.rectangle(binary_warped, (rect[0], rect[1]), (rect[2], rect[3]), rect_color, 2)\n",
    "            \n",
    "            # draw the right rectangle\n",
    "            for rect, is_good in zip(right_windows, is_right_window_good):\n",
    "                if is_good:\n",
    "                    rect_color = (0, 255, 0)\n",
    "                else:\n",
    "                    rect_color = (255, 0, 0)\n",
    "                cv2.rectangle(binary_warped, (rect[0], rect[1]), (rect[2], rect[3]), rect_color, 2)\n",
    "            \n",
    "            if direction > 0:\n",
    "                cv2.putText(binary_warped, \"RIGHT\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,\n",
    "                        cv2.LINE_AA)\n",
    "            elif direction < 0:\n",
    "                cv2.putText(binary_warped, \"LEFT\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,\n",
    "                        cv2.LINE_AA)\n",
    "            else:\n",
    "                cv2.putText(binary_warped, \"CENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,\n",
    "                        cv2.LINE_AA)\n",
    "            \n",
    "            self.__debug_dict['line_trace'] = binary_warped\n",
    "            \n",
    "            \n",
    "        return left_fit, right_fit, pts_left, pts_right, left_windows, \\\n",
    "                right_windows, is_left_window_good, is_right_window_good\n",
    "\n",
    "    def filter_non_line_element(self, image):\n",
    "        #image_edge = cv2.Canny( image, 0, 255);\n",
    "        aspect_ratio_lower_limit = 1.5\n",
    "        convex_per_to_area_ratio_lower_limit = 0.07\n",
    "        area_upper_limit = 0.1\n",
    "        try:\n",
    "            total_area = image.shape[0] * image.shape[1]\n",
    "            im2, cnts, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]\n",
    "\n",
    "            #print('debug, find contours: ', len(cnts))\n",
    "            result = np.zeros_like(image)\n",
    "            if 'remove_block' in self.__debug_dict:\n",
    "                remove_part = self.__debug_dict['remove_block']\n",
    "            else:\n",
    "                remove_part = np.zeros_like(image)\n",
    "\n",
    "            for c in cnts:\n",
    "                hull = cv2.convexHull(c)\n",
    "                peri = cv2.arcLength(hull, True)\n",
    "                area_c = cv2.contourArea(hull)\n",
    "                area = cv2.contourArea(c)\n",
    "\n",
    "                if area < total_area * area_upper_limit:\n",
    "                    if(peri / area_c) > 0.07:\n",
    "                        cv2.drawContours(result, [c], 0, 1, cv2.FILLED)\n",
    "                    else:\n",
    "                        center, dim,r = cv2.minAreaRect(c)\n",
    "                        if (dim[0] > dim[1] * 1.5 or dim[1] > dim[0] * 1.5):\n",
    "                            cv2.drawContours(result, [c], 0, 1, cv2.FILLED)\n",
    "                        else:\n",
    "                            cv2.drawContours(remove_part, [c], 0, 255, cv2.FILLED)\n",
    "                            #print('debug: peri/area', peri, area, peri/area, dim[0], dim[1])\n",
    "\n",
    "            self.__debug_dict['remove_block'] = remove_part\n",
    "            return result\n",
    "            \n",
    "        except:\n",
    "            return image\n",
    "\n",
    "    def feature_extraction(self, image):\n",
    "        \n",
    "        img_birdview_bin = self.camera.transform_to_bird_view(image)\n",
    "        \n",
    "        edge, white, yellow = self.road_feature_detector.collect_road_features(img_birdview_bin)\n",
    "        #edge = self.road_feature_detector.remove_non_line_structure(edge)\n",
    "        #white = self.road_feature_detector.remove_non_line_structure(white) \n",
    "        #yellow = self.road_feature_detector.remove_non_line_structure(yellow)\n",
    "        \n",
    "        if False:\n",
    "            ckernel = cv2.getStructuringElement(cv2.MORPH_RECT,(15,15))\n",
    "            okernel = cv2.getStructuringElement(cv2.MORPH_RECT,(5,5))\n",
    "            edge = cv2.morphologyEx(edge, cv2.MORPH_CLOSE, ckernel)\n",
    "            white = cv2.morphologyEx(white, cv2.MORPH_CLOSE, ckernel)\n",
    "            yellow = cv2.morphologyEx(yellow, cv2.MORPH_CLOSE, ckernel)\n",
    "\n",
    "            #remove small linkage between components\n",
    "            edge = cv2.morphologyEx(edge, cv2.MORPH_OPEN, okernel)\n",
    "            white = cv2.morphologyEx(white, cv2.MORPH_OPEN, okernel)\n",
    "            yellow = cv2.morphologyEx(yellow, cv2.MORPH_OPEN, okernel)\n",
    "\n",
    "            # find out the countour\n",
    "            edge = self.filter_non_line_element(edge)\n",
    "            white = self.filter_non_line_element(white)\n",
    "            yellow = self.filter_non_line_element(yellow)\n",
    "        \n",
    "        img_birdview_bin = np.zeros_like(edge)\n",
    "        \n",
    "        img_birdview_bin[edge > 0] = self.param.edge_pixel_weighting\n",
    "        img_birdview_bin[white > 0] = self.param.white_pixel_weighting\n",
    "        img_birdview_bin[yellow > 0] = self.param.yellow_pixel_weighting\n",
    "        \n",
    "        if self.__debug_flag:\n",
    "            self.__debug_dict['feature'] = np.dstack((edge, yellow, white)) * 255\n",
    "\n",
    "        return img_birdview_bin\n",
    "\n",
    "    def __create_final_image(self, image, image_bird_view_bin, camera, left_lane, right_lane):\n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(image_bird_view_bin).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        ploty = np.linspace(0, image_bird_view_bin.shape[0] - 1, image_bird_view_bin.shape[0])\n",
    "        left_fitx = left_lane.line_x_pos(ploty)\n",
    "        right_fitx = right_lane.line_x_pos(ploty)\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        color_warp[left_lane.pixels[:,1], left_lane.pixels[:,0]] = [255, 0, 0]\n",
    "        color_warp[right_lane.pixels[:,1], right_lane.pixels[:,0]] = [0, 0, 255]\n",
    "        \n",
    "        debug_color_warp = np.copy(color_warp)\n",
    "        \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = camera.transform_to_camera_view(color_warp)\n",
    "\n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(image, 1, newwarp, 0.5, 0)\n",
    "\n",
    "        if(self.__debug_flag):\n",
    "            image_bird_view = self.camera.transform_to_bird_view(image)\n",
    "            \n",
    "            cv2.polylines(debug_color_warp, np.int_([pts_left]), False, (255,255,0), 5)\n",
    "            cv2.polylines(debug_color_warp, np.int_([pts_right]), False, (255,255,0), 5)\n",
    "                \n",
    "            self.__debug_dict['feature_color'] = cv2.addWeighted(image_bird_view, 1, debug_color_warp, 0.8, 0)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __add_driving_info(self, image, left_curve, right_curve, off_center):\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        curvature = 0.5 * (left_curve + right_curve)\n",
    "        cv2.putText(image, \"Radius of curvature = %.2f(m)\" % curvature, (10, 30), font, 1, (255, 255, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.putText(image, \"Vehicle is %.2fm left of center\" % off_center, (10, 60), font, 1, (255, 255, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def detect_lane(self, img_birdview_bin, direction=0):\n",
    "        left_fit, right_fit, left_lane_inds, right_lane_inds, \\\n",
    "            left_window,right_windows, is_left_window_good, is_right_window_good \\\n",
    "            = self.__find_left_and_right_lane_conv(img_birdview_bin, self.param.find_lane_weighting,\n",
    "                                              self.param.find_lane_left_lane_pos,\n",
    "                                              self.param.find_lane_right_lane_pos,\n",
    "                                              self.param.find_lane_lane_sigma,\n",
    "                                              self.param.find_lane_no_detect_window_y,\n",
    "                                              self.param.find_lane_window_margin_x,\n",
    "                                              self.param.find_lane_min_pixel,\n",
    "                                              direction)\n",
    "        \n",
    "        left_lane = Lane(left_fit)\n",
    "        left_lane.set_lane_line_detection_windows(left_window, is_left_window_good)\n",
    "        left_lane.set_lane_line_pixel(left_lane_inds)\n",
    "\n",
    "        right_lane = Lane(right_fit)\n",
    "        right_lane.set_lane_line_detection_windows(right_windows, is_right_window_good)\n",
    "        right_lane.set_lane_line_pixel(right_lane_inds)\n",
    "\n",
    "        return left_lane, right_lane\n",
    "\n",
    "    \n",
    "    def average_slope(self, lines):\n",
    "        slopes = []\n",
    "        weights = []\n",
    "\n",
    "        ttl_dst_right = 0.\n",
    "        ttl_dst_left = 0.\n",
    "        \n",
    "        if lines is None:\n",
    "            return None\n",
    "        \n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                slope = ((y2-y1)/(x2-x1))\n",
    "                b = y1-slope*x1\n",
    "                dist = int(math.sqrt((x2-x1)*(x2-x1) + (y2-y1)*(y2-y1)))\n",
    "                for i in range(0, dist, 20):\n",
    "                    slopes.append(slope)\n",
    "        \n",
    "        return np.median(slopes)\n",
    "\n",
    "    def hough_line(self, image):\n",
    "        ksize = 7\n",
    "        low_threshold = 50\n",
    "        high_threshold = 150\n",
    "        rho = 2\n",
    "        theta = 1\n",
    "        threshold = 20\n",
    "        min_line = 70\n",
    "        line_grap = 10\n",
    "        \n",
    "        image_new = np.copy(image)\n",
    "        lines = cv2.HoughLinesP(image, rho, theta*np.pi/180, threshold, np.array([]),\\\n",
    "                                minLineLength=min_line, maxLineGap=line_grap)\n",
    "            \n",
    "        if self.__debug_flag:\n",
    "            debug_hough = np.copy(image)\n",
    "            debug_hough = cv2.cvtColor(debug_hough, cv2.COLOR_GRAY2RGB);\n",
    "            \n",
    "            if lines is not None:\n",
    "                for line in lines:\n",
    "                    for x1,y1,x2,y2 in line:\n",
    "                        cv2.line(debug_hough, (x1, y1), (x2, y2), (0,0,255), 3)\n",
    "            self.__debug_dict['hough'] = debug_hough\n",
    "            \n",
    "        return lines\n",
    "    \n",
    "    def check_vector_helper(self, img_birdview_bin):\n",
    "        lines = self.hough_line(img_birdview_bin)\n",
    "        return self.average_slope(lines)\n",
    "\n",
    "    \n",
    "    def determine_heading_direction(self, vector_all):\n",
    "        # TODO: find out the threshold here\n",
    "        if(vector_all > -0.6 and vector_all < 0):\n",
    "            direction = 1\n",
    "        elif(vector_all < 0.6 and vector_all > 0):\n",
    "            direction = -1\n",
    "        else:\n",
    "            direction = 0\n",
    "            \n",
    "        return direction\n",
    "    \n",
    "    def augmented_image(self, image):\n",
    "        if(self.__debug_flag):\n",
    "            self.__debug_dict = {}\n",
    "\n",
    "        img_birdview_bin = self.feature_extraction(image)\n",
    "        img_birdview_bin[img_birdview_bin.shape[0]*59//60:,] = 0\n",
    "        \n",
    "        #check orientation\n",
    "        vector_all = self.check_vector_helper(img_birdview_bin)\n",
    "        if vector_all is None:\n",
    "            vector_all = 0\n",
    "            \n",
    "        direction = self.determine_heading_direction(vector_all)\n",
    "\n",
    "        left_lane, right_lane = self.detect_lane(img_birdview_bin, direction)\n",
    "        left_lane.calc_real_scale(self.camera.ym_per_pix, self.camera.xm_per_pix)\n",
    "        right_lane.calc_real_scale(self.camera.ym_per_pix, self.camera.xm_per_pix)\n",
    "\n",
    "        y_eval =  image.shape[0] * self.camera.ym_per_pix\n",
    "        left_curve = left_lane.line_curvature_real_scale(y_eval)\n",
    "        right_curve = right_lane.line_curvature_real_scale(y_eval)\n",
    "\n",
    "        left_base = left_lane.line_base_real_scale(y_eval)\n",
    "        right_base = right_lane.line_base_real_scale(y_eval)\n",
    "\n",
    "        lane_width = image.shape[1] * self.camera.xm_per_pix\n",
    "        off_center = (right_base + left_base) / 2 - lane_width / 2\n",
    "\n",
    "        image = self.__create_final_image(image, img_birdview_bin, self.camera, left_lane, right_lane)\n",
    "        image = self.__add_driving_info(image, left_curve, right_curve, off_center)\n",
    "\n",
    "        if (self.__debug_flag):\n",
    "            image_remove_block = self.__debug_dict.get('remove_block')\n",
    "            \n",
    "            image_histogram = self.__debug_dict.get('histogram')\n",
    "            if not (image_histogram is None):\n",
    "                image_histogram = Image.fromarray(\n",
    "                    cv2.resize(image_histogram, (image.shape[1] // 2, image.shape[0] // 6), interpolation=cv2.INTER_CUBIC))\n",
    "                image_histogram = image_histogram.convert('RGBA')\n",
    "                image_histogram.putalpha(128)\n",
    "\n",
    "            enhanced_image = self.road_feature_detector.debug_dict['enhanced']\n",
    "            mask_color = self.road_feature_detector.debug_dict['mask']\n",
    "            feature_color = self.__debug_dict['feature']\n",
    "            image_birdview_lane = self.__debug_dict['feature_color']\n",
    "            image_hough = self.__debug_dict['hough']\n",
    "            image_line_trace = self.__debug_dict.get('line_trace')\n",
    "            \n",
    "            #shit\n",
    "            #mask_color = image_remove_block\n",
    "\n",
    "            debug_im = Image.new('RGB', (image.shape[1] * 3 // 2, image.shape[0] * 3 // 2))\n",
    "\n",
    "            debug_im.paste(Image.fromarray(image), (0, 0))\n",
    "\n",
    "            cv2.putText(image_hough, \"Slope average = %.2f\" % vector_all, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "            debug_im.paste(\n",
    "                Image.fromarray(cv2.resize(image_hough, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)),\n",
    "                (0, image.shape[0]))\n",
    "\n",
    "            if image_line_trace is not None:\n",
    "                debug_im.paste(Image.fromarray(\n",
    "                    cv2.resize(image_line_trace, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)),\n",
    "                               (image.shape[1] // 2, image.shape[0]))\n",
    "\n",
    "            debug_im.paste(\n",
    "                Image.fromarray(cv2.resize(mask_color, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)),\n",
    "                (image.shape[1], 0))\n",
    "\n",
    "            debug_im.paste(\n",
    "                Image.fromarray(cv2.resize(feature_color, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)),\n",
    "                (image.shape[1], image.shape[0] // 2))\n",
    "\n",
    "            debug_im.paste(\n",
    "                Image.fromarray(cv2.resize(image_birdview_lane, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)),\n",
    "                (image.shape[1], image.shape[0]))\n",
    "\n",
    "            if not(image_histogram is None):\n",
    "                debug_im.paste(image_histogram, (image.shape[1] // 2, image.shape[0] + image.shape[0] // 3), image_histogram)\n",
    "\n",
    "            return np.array(debug_im), left_lane, right_lane\n",
    "        else:\n",
    "            return image, left_lane, right_lane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video lane detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoLaneDetector(LaneDetector):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.prev_left_lane = None\n",
    "        self.prev_right_lane = None\n",
    "        self.measure_lane_width_data = []\n",
    "        self.heading_direction = 0\n",
    "        self.prev_lane_cnt = 0 \n",
    "        \n",
    "        # debug message\n",
    "        self.debug_prev_frame_status = \"\"\n",
    "        self.debug_current_frame_status = \"\"\n",
    "        self.debug_final_chosen_lane = \"\"\n",
    "\n",
    "    def __output_debug_message(self, image, start_pos):\n",
    "        debug_message = []\n",
    "        debug_message.append(\"Previous lane filter: %s\" % self.debug_prev_frame_status) # skip, success, failed\n",
    "        debug_message.append(\"Lane finding in current frame: %s\" % self.debug_current_frame_status)  # skip, success, failed\n",
    "        debug_message.append(\"Last high confidence lane pair found at: %d\" % self.prev_lane_cnt) # output the frame value\n",
    "        debug_message.append(\"Final chosen lane: %s\" % self.debug_final_chosen_lane) # previous lane filter, recaculate, previous frame\n",
    "        \n",
    "        y_pos = 30\n",
    "        for message in debug_message:\n",
    "            cv2.putText(image, message, (720, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            y_pos = y_pos + 25\n",
    "        \n",
    "    def augmented_image(self, image):\n",
    "        out_image, left_fit, right_fit = super().augmented_image(image)\n",
    "        \n",
    "        if(self._LaneDetector__debug_flag):\n",
    "            self.__output_debug_message(out_image, image.shape[0])\n",
    "\n",
    "        return out_image, left_fit, right_fit\n",
    "    \n",
    "    def __lane_pair_error(self, left_lane, right_lane, image_shape):\n",
    "        left_lane_base = left_lane.line_x_pos(image_shape[0])\n",
    "        right_lane_base = right_lane.line_x_pos(image_shape[0])\n",
    "                \n",
    "        lane_width = right_lane_base - left_lane_base\n",
    "        expect_lane = self.exp_lane_width_meter / self.camera.xm_per_pix\n",
    "        \n",
    "        return abs(lane_width - expect_lane) / expect_lane\n",
    "    \n",
    "    def determine_heading_direction(self, vector_all):\n",
    "        # to center\n",
    "        if vector_all >= 0.6 or vector_all <= -0.6:\n",
    "            self.heading_direction = 0\n",
    "        \n",
    "        if(self.heading_direction == 0 and vector_all > -0.6 and vector_all < 0):\n",
    "            self.heading_direction = 1\n",
    "        elif(self.heading_direction == 0 and vector_all < 0.6 and vector_all > 0):\n",
    "            self.heading_direction = -1\n",
    "            \n",
    "        return self.heading_direction\n",
    "    \n",
    "    def __find_approx_lane_width(self, result_left_lane, result_right_lane, y_pos):\n",
    "        if len(self.measure_lane_width_data) < 4:\n",
    "            left_lane_base = result_left_lane.line_x_pos(y_pos)\n",
    "            right_lane_base = result_right_lane.line_x_pos(y_pos)\n",
    "            lane_width = (right_lane_base - left_lane_base) * self.camera.xm_per_pix\n",
    "            self.measure_lane_width_data.append(min(lane_width, self.exp_lane_width_meter))\n",
    "            print('detect lane: %.3f' % lane_width)\n",
    "        elif len(self.measure_lane_width_data) == 4:\n",
    "            self.exp_lane_width_meter = np.mean(self.measure_lane_width_data) \n",
    "            print('detect lane: %.3f' % self.exp_lane_width_meter)\n",
    "            self.measure_lane_width_data.append(0)\n",
    "    \n",
    "    def __parallel_test(self, left_lane, right_lane, test_length):\n",
    "        lane_dist = []\n",
    "        is_cross = False\n",
    "        for i in range(0, test_length+1, 100):\n",
    "            leftx_pos = left_lane.line_x_pos(i)\n",
    "            rightx_pos = right_lane.line_x_pos(i)\n",
    "            difference = (rightx_pos - leftx_pos)\n",
    "            if difference < 0:\n",
    "                is_cross = True\n",
    "            difference = difference * self.camera.xm_per_pix \n",
    "            lane_dist.append(difference)\n",
    "            \n",
    "        return np.median(lane_dist), np.std(lane_dist) / self.exp_lane_width_meter, is_cross\n",
    "    \n",
    "    def __sanity_check(self, left_lane, right_lane, img_width, base_y_po, info=\"ERROR\"):\n",
    "        '''Total score of 7'''\n",
    "        result = []\n",
    "        debug_msg = \"\"\n",
    "    \n",
    "        if left_lane is None or right_lane is None:\n",
    "            result = [0, 0, -10, 0, 0, 0]\n",
    "            debug_msg = \"LN_BS: F LN_W: F LN_PR: F LN_ER: F !\"+info\n",
    "            return result, debug_msg\n",
    "        \n",
    "        left_lane_base = left_lane.line_x_pos(base_y_po)\n",
    "        right_lane_base = right_lane.line_x_pos(base_y_po)\n",
    "        \n",
    "        \n",
    "        # True false question\n",
    "        if (left_lane_base > img_width //2 or \\\n",
    "               right_lane_base < img_width //2):\n",
    "            lane_base_score = 0\n",
    "        else:\n",
    "            lane_base_score = 1\n",
    "            \n",
    "        result.append(lane_base_score)\n",
    "        debug_msg = debug_msg + (\"LN_BS: %.1f \" % lane_base_score)\n",
    "            \n",
    "        left_lane_radius = left_lane.line_curvature(base_y_po)\n",
    "        right_lane_radius = right_lane.line_curvature(base_y_po)\n",
    "        \n",
    "        # Return as a number, 100% = same, 0% = not the same\n",
    "        diff_radius = min(left_lane_radius / right_lane_radius, right_lane_radius / left_lane_radius)\n",
    "        if diff_radius < 0.4:\n",
    "            diff_radius_score = 0\n",
    "        elif diff_radius < 0.6:\n",
    "            diff_radius_score = 0.3\n",
    "        elif diff_radius < 0.8:\n",
    "            diff_radius_score = 0.8\n",
    "        else:\n",
    "            diff_radius_score = 1\n",
    "        \n",
    "        result.append(diff_radius_score)\n",
    "        debug_msg = debug_msg + (\"LN_BR: %.1f \" % diff_radius_score)\n",
    "            \n",
    "        mean_dist, norm_std, is_cross = self.__parallel_test(left_lane, right_lane, base_y_po)\n",
    "        lane_dist_near_car = (right_lane.line_x_pos(base_y_po) - left_lane.line_x_pos(base_y_po)) * self.camera.xm_per_pix \n",
    "        \n",
    "        \n",
    "        lane_ptg = min(lane_dist_near_car / self.exp_lane_width_meter,  self.exp_lane_width_meter / lane_dist_near_car)\n",
    "        if lane_ptg < 0.5:\n",
    "            lane_width_score = 0\n",
    "        elif lane_ptg < 0.75:\n",
    "            lane_width_score = 0.5\n",
    "        else:\n",
    "            lane_width_score = 1\n",
    "        \n",
    "        result.append(lane_width_score)\n",
    "        debug_msg = debug_msg + (\"LN_W: %.1f \" % lane_width_score)\n",
    "        \n",
    "        \n",
    "        if is_cross:\n",
    "            is_cross_score = -10\n",
    "        else:\n",
    "            is_cross_score = 1\n",
    "        \n",
    "        debug_msg = debug_msg + (\"LN_CRS: %.1f\" % is_cross_score)\n",
    "        result.append(is_cross_score)\n",
    "            \n",
    "        # Return as boolean, T no cross, F cross, critical error\n",
    "        \n",
    "        if (norm_std > 0.3):\n",
    "            parallel_test = 0\n",
    "        elif (norm_std > 0.2):\n",
    "            parallel_test = 0.5\n",
    "        else:\n",
    "            parallel_test = 1\n",
    "        result.append(parallel_test)\n",
    "        debug_msg = debug_msg + (\"LN_PR: %.1f \" % parallel_test)\n",
    "\n",
    "        max_point = 36000\n",
    "        max_ypoint = base_y_po\n",
    "        # These should not be return,\n",
    "        \n",
    "        margin = 50\n",
    "        nonzerox = left_lane.pixels[:,1]\n",
    "        nonzeroy = left_lane.pixels[:,0]\n",
    "        left_fit = left_lane.polyfit\n",
    "        try:\n",
    "            left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "            left_point_cnt = min(max_point, len(left_lane_inds))\n",
    "            left_ypoint_cnt = len(np.unique(nonzeroy[left_lane_inds]))\n",
    "        except:\n",
    "            left_point_cnt = 0 \n",
    "            left_ypoint_cnt = 0\n",
    "            \n",
    "        nonzerox = right_lane.pixels[:,1]\n",
    "        nonzeroy = right_lane.pixels[:,0]\n",
    "        right_fit = right_lane.polyfit\n",
    "        try:\n",
    "            right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "            right_point_cnt = min(max_point, len(right_lane_inds))\n",
    "            right_ypoint_cnt = len(np.unique(nonzeroy[right_lane_inds]))\n",
    "        except:\n",
    "            right_point_cnt = 0 \n",
    "            right_ypoint_cnt = 0\n",
    "        \n",
    "        point_score = (left_point_cnt + right_point_cnt) / max_point / 2\n",
    "        ypoint_score = (left_ypoint_cnt + right_ypoint_cnt) / max_ypoint / 2\n",
    "        result.append(point_score)\n",
    "        result.append(ypoint_score)\n",
    "        debug_msg = debug_msg + (\"LN_PT: %.3f\" %  point_score )\n",
    "        debug_msg = debug_msg + (\"LN_YPT: %.3f\" %  ypoint_score )\n",
    "        \n",
    "        filename = \"./error_score.txt\"\n",
    "        file = open(filename, \"a\")\n",
    "        file.write(\"%.2f, %.2f, %2.f, %2.f, %.2f, %.2f, %.2f\\n\" % (lane_base_score, diff_radius_score, \n",
    "                   lane_width_score, is_cross_score, parallel_test, point_score, ypoint_score))\n",
    "        file.close\n",
    "            \n",
    "        return result, debug_msg\n",
    "    \n",
    "    def detect_lane(self, img_birdview_bin, direction):\n",
    "        working = False\n",
    "        h,w = img_birdview_bin.shape\n",
    "        image_shape = img_birdview_bin.shape\n",
    "        temp_left_lane = None\n",
    "        temp_right_lane = None\n",
    "        left_lane = None\n",
    "        right_lane = None\n",
    "                \n",
    "        if(not(self.prev_left_lane is None) and not(self.prev_right_lane is None)):\n",
    "            try:\n",
    "                if self.prev_lane_cnt < 8:\n",
    "                    left_fit, right_fit, left_lane_inds, right_lane_inds, \\\n",
    "                        left_window, right_windows, is_left_window_good, is_right_window_good \\\n",
    "                        = self.__find_left_and_right_lane_by_prev_high_conf(img_birdview_bin,\n",
    "                                                                       self.prev_left_lane, \n",
    "                                                                       self.prev_right_lane)\n",
    "                else:\n",
    "                    left_fit, right_fit, left_lane_inds, right_lane_inds, \\\n",
    "                        left_window, right_windows, is_left_window_good, is_right_window_good \\\n",
    "                        = self.__find_left_and_right_lane_by_prev_conv(img_birdview_bin, self.param.find_lane_weighting, \n",
    "                                                                       self.prev_left_lane, \n",
    "                                                                       self.prev_right_lane,\n",
    "                                                                       self.param.find_lane_lane_sigma,\n",
    "                                                                       self.param.find_lane_no_detect_window_y,\n",
    "                                                                       self.param.find_lane_window_margin_x,\n",
    "                                                                       self.param.find_lane_min_pixel,\n",
    "                                                                       direction\n",
    "                                                                      )\n",
    "                #  __find_left_and_right_lane_by_prev_conv\n",
    "                \n",
    "                temp_left_lane = Lane(left_fit)\n",
    "                temp_right_lane = Lane(right_fit)\n",
    "                \n",
    "                temp_left_lane.set_lane_line_detection_windows(left_window, is_left_window_good)\n",
    "                temp_left_lane.set_lane_line_pixel(left_lane_inds)\n",
    "\n",
    "                temp_right_lane.set_lane_line_detection_windows(right_windows, is_right_window_good)\n",
    "                temp_right_lane.set_lane_line_pixel(right_lane_inds)\n",
    "                \n",
    "                sanity_result_prev, self.debug_prev_frame_status = self.__sanity_check(temp_left_lane, temp_right_lane, w, h)\n",
    "                \n",
    "                if np.sum(sanity_result_prev) > 5:\n",
    "                    working = True\n",
    "                else:\n",
    "                    working = False\n",
    "                \n",
    "            except Exception as ex:\n",
    "                sanity_result_prev, self.debug_prev_frame_status = self.__sanity_check(None, None, w, h)\n",
    "                working = False \n",
    "                traceback.print_exc()\n",
    "        else:\n",
    "            sanity_result_prev, self.debug_prev_frame_status = self.__sanity_check(None, None, w, h, 'NO PREV')\n",
    "        \n",
    "        if not working:\n",
    "            try:\n",
    "                left_fit, right_fit, left_lane_inds, right_lane_inds, \\\n",
    "                    left_window,right_windows, is_left_window_good, is_right_window_good \\\n",
    "                    = self._LaneDetector__find_left_and_right_lane_conv(img_birdview_bin, self.param.find_lane_weighting,\n",
    "                                                      self.param.find_lane_left_lane_pos,\n",
    "                                                      self.param.find_lane_right_lane_pos,\n",
    "                                                      self.param.find_lane_lane_sigma,\n",
    "                                                      self.param.find_lane_no_detect_window_y,\n",
    "                                                      self.param.find_lane_window_margin_x,\n",
    "                                                      self.param.find_lane_min_pixel,\n",
    "                                                      direction)\n",
    "                left_lane = Lane(left_fit)\n",
    "                right_lane = Lane(right_fit)\n",
    "                \n",
    "                left_lane.set_lane_line_detection_windows(left_window, is_left_window_good)\n",
    "                left_lane.set_lane_line_pixel(left_lane_inds)\n",
    "\n",
    "                right_lane.set_lane_line_detection_windows(right_windows, is_right_window_good)\n",
    "                right_lane.set_lane_line_pixel(right_lane_inds)\n",
    "                \n",
    "                sanity_result_curr, self.debug_current_frame_status = self.__sanity_check(left_lane, right_lane, w, h)\n",
    "                    \n",
    "            except Exception as ex:\n",
    "                sanity_result_curr, self.debug_current_frame_status = self.__sanity_check(None, None, w, h)\n",
    "                traceback.print_exc()\n",
    "                working = False\n",
    "        else:\n",
    "            sanity_result_curr, self.debug_current_frame_status = self.__sanity_check(None, None, w, h, \"SKIP\")\n",
    "        \n",
    "        sanity_score_prev = np.sum(sanity_result_prev)\n",
    "        sanity_score_curr = np.sum(sanity_result_curr)\n",
    "        \n",
    "        if sanity_score_curr >= sanity_score_prev and sanity_score_curr > 4.5:\n",
    "            if sanity_score_curr > 5:\n",
    "                self.prev_left_lane = left_lane\n",
    "                self.prev_right_lane = right_lane\n",
    "                self.prev_lane_cnt = 0 \n",
    "                self.__find_approx_lane_width(left_lane, right_lane, h)\n",
    "            else:\n",
    "                self.prev_lane_cnt += 1\n",
    "            self.debug_final_chosen_lane = \"CURRENT\"\n",
    "            return left_lane, right_lane \n",
    "        elif sanity_score_prev > sanity_score_curr and sanity_score_prev > 4.5:\n",
    "            if sanity_score_prev > 5:\n",
    "                self.prev_left_lane = temp_left_lane\n",
    "                self.prev_right_lane = temp_right_lane\n",
    "                self.prev_lane_cnt = 0 \n",
    "                self.__find_approx_lane_width(temp_left_lane, temp_right_lane, h)\n",
    "            else:\n",
    "                self.prev_lane_cnt += 1\n",
    "            self.debug_final_chosen_lane = \"FILTER PREV\"\n",
    "            self._LaneDetector__debug_dict['line_trace'] = self._LaneDetector__debug_dict['line_trace_prev']\n",
    "            return temp_left_lane, temp_right_lane\n",
    "        else:\n",
    "            if self.prev_left_lane is None or self.prev_right_lane is None:\n",
    "                self.debug_final_chosen_lane = \"CURRENT\"\n",
    "                return left_lane, right_lane \n",
    "            else:\n",
    "                self.debug_final_chosen_lane = \"PREV LANE\"\n",
    "                return self.prev_left_lane, self.prev_right_lane\n",
    "            \n",
    "    def __find_left_and_right_lane_by_prev_high_conf(self, binary_warped, left_lane, right_lane):\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "        left_fit = left_lane.polyfit\n",
    "        right_fit = right_lane.polyfit\n",
    "        \n",
    "        margin = 100\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "        left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "        left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "        right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "        right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        pts_left = np.transpose(np.vstack([leftx, lefty]))\n",
    "        pts_right = np.transpose(np.vstack([rightx, righty]))\n",
    "        \n",
    "        if(self._LaneDetector__debug_flag):\n",
    "            # add the line fitting result here\n",
    "            debug_iamge = np.zeros_like(binary_warped)\n",
    "            debug_iamge[binary_warped>0] = 255\n",
    "            debug_iamge = cv2.cvtColor(debug_iamge, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            # Plot the curve\n",
    "            ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "            left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "            right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "            \n",
    "            # Draw the lane onto the warped blank image\n",
    "            left_line_pts = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "            right_line_pts = np.array([np.transpose(np.vstack([right_fitx, ploty]))])\n",
    "            \n",
    "            cv2.fillPoly(debug_iamge, np.int_([left_line_pts]), (0,0, 255))\n",
    "            cv2.fillPoly(debug_iamge, np.int_([right_line_pts]), (0,0, 255))\n",
    "            \n",
    "            # Draw the windows\n",
    "            left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "            left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                          ploty])))])\n",
    "            left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "            right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "            right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                          ploty])))])\n",
    "            right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "            cv2.fillPoly(debug_iamge, np.int_([left_line_pts]), (0,255, 0))\n",
    "            cv2.fillPoly(debug_iamge, np.int_([right_line_pts]), (0,255, 0))\n",
    "            \n",
    "            \n",
    "            self._LaneDetector__debug_dict['line_trace_prev'] = debug_iamge\n",
    "        \n",
    "        return left_fit, right_fit, pts_left, pts_right, [], \\\n",
    "                [], [True], [True]\n",
    "    \n",
    "    def __find_left_and_right_lane_by_prev_conv(self, binary_warped, weighting_func, left_lane, right_lane, lane_sigma,\n",
    "                                               no_detect_window_y = 27, window_margin_x = 100, min_pixel = 20, beyond=10):\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "        window_width = 50 \n",
    "        window_height = np.int(binary_warped.shape[0] / no_detect_window_y)\n",
    "        margin = window_margin_x\n",
    "        minpix = min_pixel\n",
    "\n",
    "        window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "\n",
    "        # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "        # and then np.convolve the vertical image slice with the window template \n",
    "        left_lane_base = left_lane.line_x_pos(binary_warped.shape[1])\n",
    "        right_lane_base = right_lane.line_x_pos(binary_warped.shape[1])\n",
    "        l_center, r_center = self._LaneDetector__find_left_and_right_base_conv(binary_warped, window, \n",
    "                                                                               left_lane_base, right_lane_base, lane_sigma)\n",
    "        \n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        left_windows = []\n",
    "        right_windows = []\n",
    "        is_left_window_good = []\n",
    "        is_right_window_good = []\n",
    "        \n",
    "        win_y_low = int(binary_warped.shape[0]-window_height)\n",
    "        win_y_high = int(binary_warped.shape[0])\n",
    "        win_xleft_low = l_center - window_width//2\n",
    "        win_xleft_high  = l_center + window_width//2\n",
    "        win_xright_low = r_center - window_width//2\n",
    "        win_xright_high = r_center + window_width//2\n",
    "        left_windows.append((win_xleft_low, win_y_low, win_xleft_high, win_y_high))\n",
    "        right_windows.append((win_xright_low, win_y_low, win_xright_high, win_y_high))        \n",
    "\n",
    "        # Go through each layer looking for max pixel locations\n",
    "        for level in range(1,(int)(binary_warped.shape[0]/window_height)):\n",
    "            win_y_low = int(binary_warped.shape[0]-(level+1)*window_height)\n",
    "            win_y_high = int(binary_warped.shape[0]-level*window_height)\n",
    "            \n",
    "            # convolve the window into the vertical slice of the image\n",
    "            image_layer = np.sum(binary_warped[win_y_low:win_y_high,:], axis=0)\n",
    "            conv_signal = np.convolve(window, image_layer)\n",
    "            # Find the best left centroid by using past left center as a reference\n",
    "            # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "            offset = window_width//2\n",
    "            l_min_index = int(max(l_center+offset-margin,0))\n",
    "            l_max_index = int(min(l_center+offset+margin,binary_warped.shape[1]))\n",
    "            l_center_t = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "            # Find the best right centroid by using past right center as a reference\n",
    "            r_min_index = int(max(r_center+offset-margin,0))\n",
    "            r_max_index = int(min(r_center+offset+margin,binary_warped.shape[1]))\n",
    "            r_center_t = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "            \n",
    "            # only the first ten will go\n",
    "            center_y = (win_y_high + win_y_low) // 2\n",
    "            \n",
    "            if(level < beyond):\n",
    "                leftx_current = (int)(left_lane.line_x_pos(center_y))\n",
    "                rightx_current = (int)(right_lane.line_x_pos(center_y))\n",
    "            \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            \n",
    "            win_xleft_low = l_center_t - offset\n",
    "            win_xleft_high  = l_center_t + offset\n",
    "            win_xright_low = r_center_t - offset\n",
    "            win_xright_high = r_center_t + offset\n",
    "            \n",
    "            left_windows.append((win_xleft_low, win_y_low, win_xleft_high, win_y_high))\n",
    "            right_windows.append((win_xright_low, win_y_low, win_xright_high, win_y_high))\n",
    "            \n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            \n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                is_left_window_good.append(True)\n",
    "                l_center = l_center_t\n",
    "            else:\n",
    "                is_left_window_good.append(False)\n",
    "            \n",
    "            if len(good_right_inds) > minpix:   \n",
    "                is_right_window_good.append(True)\n",
    "                r_center = r_center_t\n",
    "            else:\n",
    "                is_right_window_good.append(False)\n",
    "                \n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds]\n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        \n",
    "        leftw = binary_warped[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] * \\\n",
    "            weighting_func(leftx / binary_warped.shape[1], lefty / binary_warped.shape[0])\n",
    "        rightw = binary_warped[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] * \\\n",
    "            weighting_func(rightx / binary_warped.shape[1], righty / binary_warped.shape[0])\n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2, w=leftw)\n",
    "        right_fit = np.polyfit(righty, rightx, 2, w=rightw)\n",
    "        \n",
    "        pts_left = np.transpose(np.vstack([leftx, lefty]))\n",
    "        pts_right = np.transpose(np.vstack([rightx, righty]))\n",
    "        \n",
    "        if(self._LaneDetector__debug_flag):\n",
    "            # add the line fitting result here\n",
    "            binary_warped[binary_warped>0] = 255\n",
    "            binary_warped = cv2.cvtColor(binary_warped, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            # draw the left rectangle\n",
    "            for rect, is_good in zip(left_windows, is_left_window_good):\n",
    "                if is_good:\n",
    "                    rect_color = (0, 255, 0)\n",
    "                else:\n",
    "                    rect_color = (255, 0, 0)\n",
    "                cv2.rectangle(binary_warped, (rect[0], rect[1]), (rect[2], rect[3]), rect_color, 2)\n",
    "            \n",
    "            # draw the right rectangle\n",
    "            for rect, is_good in zip(right_windows, is_right_window_good):\n",
    "                if is_good:\n",
    "                    rect_color = (0, 255, 0)\n",
    "                else:\n",
    "                    rect_color = (255, 0, 0)\n",
    "                cv2.rectangle(binary_warped, (rect[0], rect[1]), (rect[2], rect[3]), rect_color, 2)\n",
    "            \n",
    "            self._LaneDetector__debug_dict['line_trace_prev'] = binary_warped\n",
    "\n",
    "        return left_fit, right_fit, pts_left, pts_right, left_windows, \\\n",
    "                right_windows, is_left_window_good, is_right_window_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "t_images = glob.glob('./test_images/*.*')\n",
    "lane_detector = LaneDetector()\n",
    "lane_detector.set_debug_flag(True)\n",
    "\n",
    "for i, fname in enumerate(t_images):    \n",
    "    image = np.array(Image.open(fname))\n",
    "    image = image[:,:,0:3]\n",
    "    print(image.shape)\n",
    "    result, _, _ = lane_detector.augmented_image(image)\n",
    "    plt.imsave(os.path.join('./output_images', os.path.basename(fname)), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane in videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_detector = VideoLaneDetector()\n",
    "lane_detector.set_debug_flag(True)xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    global lane_detector\n",
    "    try:\n",
    "        result, left_fit, right_fit = lane_detector.augmented_image(image)\n",
    "    except Exception as ex:\n",
    "        mpimg.imsave(\"error_images/error.jpg\", image)\n",
    "        traceback.print_exc()\n",
    "        return image\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lane_detector.reset()\n",
    "\n",
    "white_output = os.path.join('./output_videos/', 'project_video.mp4')\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "previous_lane = None\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False, threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lane_detector.reset()\n",
    "\n",
    "clip2 = VideoFileClip(\"challenge_video.mp4\")\n",
    "left_fit = None\n",
    "right_fit = None\n",
    "challenge_output = os.path.join('./output_videos/', 'challenge_video.mp4')\n",
    "\n",
    "challenge_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lane_detector.reset()\n",
    "\n",
    "clip3 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "left_fit = None\n",
    "right_fit = None\n",
    "harder_challenge_output = os.path.join('./output_videos/', 'harder_challenge_video.mp4')\n",
    "\n",
    "harder_challenge_clip = clip3.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time harder_challenge_clip.write_videofile(harder_challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trash\n",
    "def weighted_median(self, a, w, p, r):\n",
    "#base case for single element\n",
    "    if r == p:\n",
    "        return a[p]\n",
    "    #base case for two elements\n",
    "    #make sure we return the average, in case the two candidates have equal weight\n",
    "    if r-p == 1:\n",
    "        if w[p] == w[r]:\n",
    "            return (a[p] + a[r])//2\n",
    "        if w[p] > w[r]:\n",
    "            return a[p]\n",
    "    else:\n",
    "        return a[r]\n",
    "\n",
    "    #partition around pivot r\n",
    "    q = partition(a, p, r)\n",
    "    wl, wg = np.sum(a[p:q]*w[p:q]), np.sum(a[q+1:r]*w[q+1:r])\n",
    "    #if partitions are balanced then we are done\n",
    "    if wl < 0.5 and wg < 0.5:\n",
    "        return a[q]\n",
    "    else:\n",
    "    #increase pivot weight by the amount of partition we eliminate\n",
    "        if wl > wg:\n",
    "            w[q] += wg\n",
    "            #recurse on pivot inclusively \n",
    "            return self.weighted_median(a, w, p, q)\n",
    "        else:\n",
    "            w[q] += wl\n",
    "            return self.weighted_median(a, w, q, r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
